{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infinite pool QBC\n",
    "\n",
    "### Import packages\n",
    "**Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Activation, Lambda\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import History, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Science**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from math import floor\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Functions\n",
    "**Plot Projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_projection(data, classification, x=0, y=1, bins=100):\n",
    "    # Calculate ranges and bins\n",
    "    xmin, xmax = np.amin(data[:,x]), np.amax(data[:,x])\n",
    "    ymin, ymax = np.amin(data[:,y]), np.amax(data[:,y])\n",
    "    xbins = np.linspace(xmin, xmax, bins)\n",
    "    ybins = np.linspace(ymin, ymax, bins)\n",
    "    # Calculate two histograms\n",
    "    allowed, _, _ = np.histogram2d(data[classification==1.0, x], data[classification==1.0, y], [xbins, ybins])\n",
    "    excluded, _, _ = np.histogram2d(data[classification==0.0, x], data[classification==0.0, y], [xbins, ybins])\n",
    "    # Calculate map\n",
    "    mapping = allowed / (allowed + excluded)\n",
    "    mapping = mapping.T\n",
    "    mapping = np.flipud(mapping)\n",
    "    # Plot\n",
    "    f, a = plt.subplots(1,1,figsize=(8,8))\n",
    "    a.matshow(mapping, extent=(xmin, xmax, ymin, ymax), cmap=\"seismic_r\")\n",
    "    print(\"({}, {})\".format(np.amin(mapping),np.amax(mapping)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = np.array([-3999.99, -4000.0, 200.0, 90.879999, 91.419997, 90.02, 90.250001, 200.02999, 102.65, 200.00984, 264.01999, 200.0199, 100.06994, -7998.919, -3999.97, -3999.97, -4381.715, 1364.5547, 2.6724445])\n",
    "maxs = np.array([3999.95, 3999.83, 3999.98, 4000.0, 3999.98, 3999.99, 4000.0, 3999.9899, 3999.9999, 3999.98, 3999.9999, 3999.97, 4000.0, 7993.83, 3999.95, 3999.94, 4132.4793, 37569812.0, 66.371989])\n",
    "\n",
    "def normalize(data):\n",
    "    # Normalize data\n",
    "    mu = (maxs + mins)/2\n",
    "    sigma = (maxs - mins)/np.sqrt(12)\n",
    "    data = (data - mu)/sigma\n",
    "    # Return\n",
    "    return data\n",
    "\n",
    "def undo_normalize(data):\n",
    "    # Normalize data\n",
    "    mu = (maxs + mins)/2.0\n",
    "    sigma = (maxs - mins)/np.sqrt(12)\n",
    "    data = data*sigma + mu\n",
    "    # Return\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oracle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_model = load_model(\"susyai.hdf5\")\n",
    "def oracle(data):\n",
    "    #print(data, oracle_model.predict(data))\n",
    "    return 1.0*(oracle_model.predict(data)[:,1] > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, normalized=True):\n",
    "    X = np.random.rand(N,19)\n",
    "    X *= (maxs - mins)\n",
    "    X += mins\n",
    "    Xnormed = normalize(X)\n",
    "    y = oracle(Xnormed).astype(np.float)\n",
    "    if normalized:\n",
    "        return (Xnormed,y)\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(Xtrain, ytrain):\n",
    "    est = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "    est.fit(Xtrain, ytrain)\n",
    "    return est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, Xtest):\n",
    "    #print(Xtest.shape)\n",
    "    prediction = model.predict_proba(Xtest)[:,1]\n",
    "    #print(prediction)\n",
    "    info = 1 - 2*np.abs(prediction-0.5)\n",
    "    return (prediction, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show model uncertainty results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_results(X, truth, prediction, info_measure, x=0, y=2):\n",
    "    print(\"{:<20}{}\".format(\"truth.shape\", ytest.shape))\n",
    "    print(\"{:<20}{}\".format(\"pred.shape\", ypred.shape))\n",
    "    print(\"{:<20}{}\".format(\"info.shape\", ysigma.shape))\n",
    "\n",
    "    f, a = plt.subplots(2,2, figsize=(16,16))\n",
    "    a[0,0].scatter(X[:,x], X[:,y], c=truth.ravel(), cmap=\"seismic_r\")\n",
    "    a[0,0].set_title(\"Truth\")\n",
    "    a[0,1].scatter(X[:,x], X[:,y], c=prediction.ravel(), cmap=\"seismic_r\")\n",
    "    a[0,1].set_title(\"Prediction\")\n",
    "    a[1,0].scatter(X[:,x], X[:,y], c=np.abs(truth-prediction), cmap=\"Reds\")\n",
    "    a[1,0].set_title(\"Difference\")\n",
    "    a[1,1].scatter(X[:,x], X[:,y], c=info_measure, cmap=\"Purples\")\n",
    "    a[1,1].set_title(\"Uncertainty\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Full grid search on step size and candidate pool size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_start = 10000                   # Start size\n",
    "list_iter = [500, 2500, 5000, 7500]                     # Number of data points added in each step\n",
    "list_sample = [1e3, 5e3, 1e4, 5e4, 1e5]                   # Size of set to be checked for uncertainty\n",
    "size_max = 100000                    # Maximum size of data set\n",
    "size_test = 1000000                   # Size of test set\n",
    "niterations = 7                      # Number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_AL = open(\"log_active_learning_grid.csv\", \"w\")\n",
    "log_AL.write(\"stepsize,samplesize,iteration,size,bce,acc\\n\")\n",
    "log_AL.flush()\n",
    "\n",
    "def log_result(log, size_iter, size_sample, iteration, size, bce, acc):\n",
    "    log.write(\"{},{},{},{},{},{}\\n\".format(size_iter, size_sample, iteration, size, bce, acc))\n",
    "    log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size_iter in list_iter:\n",
    "    for size_sample in list_sample:\n",
    "        size_sample = int(size_sample)\n",
    "        if size_sample < size_iter:\n",
    "            continue\n",
    "        for iteration in range(niterations):\n",
    "            print(\"STEP SIZE: {}\".format(size_iter))\n",
    "            print(\"SAMPLE SIZE: {}\".format(size_sample))\n",
    "            print(\"ITERATION {}\".format(iteration))\n",
    "\n",
    "            # Data set creation\n",
    "            Xtrain_AL, ytrain_AL = generate_data(size_start)\n",
    "            Xtrain_RS, ytrain_RS = deepcopy(Xtrain_AL), deepcopy(ytrain_AL)\n",
    "            Xtest, ytest = generate_data(size_test)\n",
    "\n",
    "            while len(Xtrain_AL) < size_max:\n",
    "\n",
    "                \"\"\" ACTIVE LEARNING \"\"\"\n",
    "                # Train model for active learning\n",
    "                model = train_model(Xtrain_AL, ytrain_AL)\n",
    "                # Test model performance\n",
    "                performance_AL = model_performance(model, Xtest, ytest)\n",
    "                # Store performance\n",
    "                log_result(log_AL, size_iter, size_sample, iteration, len(Xtrain_AL), performance_AL[\"bce\"], performance_AL[\"acc\"])\n",
    "                # Active sampling of new points\n",
    "                Xnew, ynew = active_sampling(model, size_sample, size_iter, random_fraction=0.0)\n",
    "                # Append new points to active learning\n",
    "                Xtrain_AL = np.vstack((Xtrain_AL, Xnew))\n",
    "                ytrain_AL = np.hstack((ytrain_AL, ynew))\n",
    "\n",
    "                \"\"\" LOG AND OUTPUT RESULTS \"\"\"\n",
    "                # Screen\n",
    "                #print(Xtrain_AL.shape, Xtrain_RS.shape)\n",
    "                print(\"stepsize: {:<5}    samplesize: {:5}    iteration: {:<3}  size: {:<5}    al-bce: {:<7}    al-acc: {:<7}\".format(\n",
    "                    size_iter,\n",
    "                    size_sample,\n",
    "                    iteration,\n",
    "                    len(Xtrain_AL)-size_iter,\n",
    "                    round(performance_AL[\"bce\"],5),\n",
    "                    round(performance_AL[\"acc\"],5)\n",
    "                ))\n",
    "            # Output data sets to file\n",
    "            al = np.hstack((Xtrain_AL, ytrain_AL.reshape(-1,1)))\n",
    "            np.savetxt(\"arrays/step_{}_{}.csv\".format(size_iter, iteration), al, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(palette=sns.hls_palette(8, l=.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw = pd.read_csv(\"log_active_learning_grid.csv\")\n",
    "# Get info from data for analysis\n",
    "stepsizes = raw['stepsize'].value_counts().keys().sort_values()\n",
    "samplesizes = raw['samplesize'].value_counts().keys().sort_values()\n",
    "niterations = raw['iteration'].value_counts().keys().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Heatmap***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Prepare dataframe for heatmap \"\"\"\n",
    "# Initialise arrays\n",
    "results = np.ones((len(stepsizes), len(samplesizes), 7))\n",
    "results *= np.nan\n",
    "\n",
    "# Fill arrays\n",
    "for i,step in enumerate(stepsizes):\n",
    "    for j,sample in enumerate(samplesizes):\n",
    "        for k in niterations:\n",
    "            try:\n",
    "                results[i,j,k] = raw[(raw['stepsize']==step) & (raw['samplesize']==sample) & (raw['iteration']== k)]['acc'].iloc[-1]\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "print(results)\n",
    "# Create dataframe\n",
    "df_mean = pd.DataFrame(np.mean(results, axis=2), columns=samplesizes, index=stepsizes)\n",
    "df_diff = pd.DataFrame(np.std(results, axis=2), columns=samplesizes, index=stepsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Best gained accuracy (mean)\")\n",
    "cmap = sns.cubehelix_palette(start=2.8, rot=.0, reverse=True, as_cmap=True)\n",
    "sns.heatmap(df_mean, vmin=0.887, vmax=0.919, linewidths=.5, cmap=cmap, square=True, annot=True, fmt='f', cbar_kws={\"label\":\"accuracy\"})\n",
    "plt.xlabel(\"size_sample\")\n",
    "plt.ylabel(\"size_select\")\n",
    "plt.savefig(\"best_gained_accuracy.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step_size in stepsizes:\n",
    "    print(\"Step size: {}\".format(step_size))\n",
    "    df = raw[raw['stepsize']==step_size]\n",
    "    samplesizes = df['samplesize'].value_counts()\n",
    "    n_samplesizes = samplesizes.count()\n",
    "    n_steps = samplesizes.iloc[0]\n",
    "    n_iterations = df['iteration'].value_counts().count()\n",
    "\n",
    "    # Create array\n",
    "    accuracies = np.zeros((n_samplesizes, int(n_steps/n_iterations), n_iterations))\n",
    "\n",
    "    # Fill array\n",
    "    sizes = samplesizes.keys().sort_values()\n",
    "    for i,size in enumerate(sizes):\n",
    "        for iteration in range(n_iterations):\n",
    "            accuracies[i, :, iteration] = df[df['samplesize'] == size][df['iteration'] == iteration]['acc']\n",
    "\n",
    "    # Get x axis\n",
    "    x = df['size'].value_counts().keys().sort_values()\n",
    "    sns.set(palette=sns.hls_palette(n_samplesizes, l=.4))\n",
    "    \n",
    "    # Plot lines and bands\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(16,10))\n",
    "    for i, size in enumerate(sizes):\n",
    "        plt.plot(x,np.mean(accuracies[i], axis=1), label='sample size: {}'.format(size))\n",
    "        band_min = np.amin(accuracies[i], axis=1)\n",
    "        band_max = np.amax(accuracies[i], axis=1)\n",
    "        plt.fill_between(x,band_min, band_max, alpha=0.3)\n",
    "    plt.xlabel(\"Train size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy development for different sample sizes (step size: {})\".format(step_size))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
